# Models - Use format: provider/model_name
# Providers: openai, anthropic, groq, ollama, gemini
# Examples:
#   openai/gpt-4
#   anthropic/claude-3-5-sonnet-20241022
#   groq/llama-3.3-70b-versatile
#   ollama/llama3
#   gemini/gemini-pro
PRO_MODEL_1=ollama/llama3:latest
PRO_MODEL_2=ollama/llama3:latest
CON_MODEL_1=ollama/llama3:latest
CON_MODEL_2=ollama/llama3:latest
JUDGE_MODEL=ollama/qwen2.5:7B

# API Keys
OPENROUTER_API_KEY=
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GROQ_API_KEY=
# Ollama Endpoints
# Local: http://127.0.0.1:11434 (Pro agents - llama3)
# Remote: ngrok tunnel (Judge - qwen)
OLLAMA_LOCAL_URL=http://127.0.0.1:11434
OLLAMA_REMOTE_URL=https://a47e26a32eaf.ngrok-free.app

# Web Search
SEARCH_ENGINE=duckduckgo
MAX_SEARCH_RESULTS=8
MAX_SCRAPED_PAGES_PER_FACTOR=5
SCRAPE_TIMEOUT=15

# Debate
DEBATE_ROUNDS=3
MAX_ARGUMENT_LENGTH=200
ALLOW_CROSS_CRITIQUE=true
MAX_FACTORS=5

# Rate Limiting
REQUEST_DELAY_SECONDS=0.5
MAX_RETRIES=3
RETRY_BACKOFF_FACTOR=2.0

# Evaluation
ENABLE_ANONYMIZATION=true
SCORING_SCALE=1-10

# Output
OUTPUT_DIR=outputs/
SAVE_TRANSCRIPTS=true
